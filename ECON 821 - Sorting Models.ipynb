{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECON 821 - Sorting Models\n",
    "### Davis Berlind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from linearmodels.iv import IVGMM\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"site_data.csv\")\n",
    "I = pd.read_csv(\"individual_data.csv\")\n",
    "Z = pd.read_csv(\"travel_costs.csv\")\n",
    "L = pd.read_csv(\"site_choice.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = Z.shape[0]\n",
    "nlocs = X.shape[0]\n",
    "\n",
    "choicesets = []\n",
    "for i in range(N):\n",
    "    choiceset = X.drop(columns=\"shares\")\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choicesets.append(choiceset)\n",
    "choicesets = np.stack(choicesets)\n",
    "\n",
    "choices = np.stack([choicesets[i,j,:] for i,j in zip(range(N), L.choice-1)])\n",
    "        \n",
    "npar = 6\n",
    "\n",
    "def NLL(par):\n",
    "    betas = par[0:npar]\n",
    "    util = choicesets @ betas\n",
    "    loglikes = choices @ betas - np.log(np.exp(util).sum(axis=1))\n",
    "    return -loglikes.sum()\n",
    "\n",
    "beta0 = np.repeat(0,npar)\n",
    "results = minimize(NLL, beta0, method = \"L-BFGS-B\", options={\"disp\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ramp: 0.043247\n",
      "restroom: -0.182959\n",
      "walleye: 1.736463\n",
      "salmon: 4.601105\n",
      "panfish: 0.386033\n",
      "cost: -0.103054\n"
     ]
    }
   ],
   "source": [
    "for val, name in zip(results.x, choiceset.columns):\n",
    "    print(\"%s: %f\" % (name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "choicesets = []\n",
    "for i in range(N):\n",
    "    choiceset = X.drop(columns=\"shares\")\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = choiceset.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = choiceset.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = choiceset.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = choiceset.walleye * I.loc[i, \"boat\"]\n",
    "    choicesets.append(choiceset)\n",
    "choicesets = np.stack(choicesets)\n",
    "\n",
    "choices = np.stack([choicesets[i,j,:] for i,j in zip(range(N), L.choice-1)])\n",
    "\n",
    "npar = 10\n",
    "\n",
    "beta0 = np.repeat(0,npar)\n",
    "results = minimize(NLL, beta0, method = \"L-BFGS-B\", options={\"disp\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ramp: -0.412716\n",
      "restroom: -0.277471\n",
      "walleye: 1.297074\n",
      "salmon: 4.560797\n",
      "panfish: 0.437940\n",
      "cost: -0.103054\n",
      "kids*panfish: -0.162631\n",
      "kids*restroom: 0.343272\n",
      "boat*ramp: 0.984083\n",
      "boat*walleye: 0.698864\n"
     ]
    }
   ],
   "source": [
    "for val, name in zip(results.x, choiceset.columns):\n",
    "    print(\"%s: %f\" % (name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.iii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL: -5137.248      \r"
     ]
    }
   ],
   "source": [
    "class BLP_Estimator:\n",
    "    def __init__(self, X, I, Z, L, betas0, thetas0, npar,\n",
    "                 bnds = None, tolerance = 1e-5, method = \"L-BFGS-B\"):\n",
    "        \n",
    "        self.N = Z.shape[0] # storing number of individuals\n",
    "        self.nlocs = X.shape[0] # storing number of locations\n",
    "        \n",
    "        # creating array of all possible choices for all individuals\n",
    "        choicesets = []\n",
    "        for i in range(self.N):\n",
    "            choiceset = pd.DataFrame({\n",
    "                \"cost\" : Z.iloc[i,].values,\n",
    "                \"kids*panfish\" : X.panfish * I.loc[i, \"kids\"],\n",
    "                \"kids*restroom\" : X.restroom * I.loc[i, \"kids\"],\n",
    "                \"boat*ramp\" : X.ramp * I.loc[i, \"boat\"],\n",
    "                \"boat*walleye\": X.walleye * I.loc[i, \"boat\"]\n",
    "            })\n",
    "            choicesets.append(choiceset)\n",
    "\n",
    "        self.choicesets = np.stack(choicesets) \n",
    "        self.locs = L.choice-1 # store site choices\n",
    "        \n",
    "        # store array of site attributes actually chosenb by each individual\n",
    "        self.choices = np.stack([self.choicesets[i,j,:] for i,j in zip(range(self.N), self.locs)])\n",
    "        \n",
    "        self.shares = X.shares\n",
    "        self.npar = npar\n",
    "        self.bnds = bnds\n",
    "        self.betas = betas0\n",
    "        self.thetas = thetas0\n",
    "        self.LL = -np.inf\n",
    "        self.method = method\n",
    "        self.tol = tolerance\n",
    "\n",
    "    def pred_p_j(self, betas):\n",
    "        \"\"\"\n",
    "        Returns predicted shares for all sites given a vector of utility parameters.\n",
    "        \"\"\"\n",
    "        util = self.thetas.transpose() + self.choicesets @ betas\n",
    "        p_ij = np.exp(util).transpose() / np.exp(util).sum(axis=1)\n",
    "        return p_ij.sum(axis=1) / self.N\n",
    "\n",
    "    def theta_update(self, betas):\n",
    "        \"\"\" \n",
    "        Returns an updated vector of thetas using a BLP contraction mapping step. \n",
    "        \"\"\"\n",
    "        p_j = self.pred_p_j(betas)\n",
    "        return self.thetas + (np.log(self.shares.values) - np.log(p_j))   \n",
    "\n",
    "    def NLL(self, par):\n",
    "        \"\"\" \n",
    "        Performs BLP contraction mapping and returns negative log-likelihood.\n",
    "        \"\"\"\n",
    "        \n",
    "        betas = par[0:self.npar] # store arbitrary vector of utility coefficients\n",
    "        d = np.repeat(1,self.nlocs) # initializing some distance\n",
    "        \n",
    "        # BLP contraction mapping\n",
    "        while any(d > self.tol):\n",
    "            thetas_new = self.theta_update(betas)\n",
    "            d = np.abs(thetas_new - self.thetas)\n",
    "            print(\"D: %.8f     \" % (max(d)), end = \"\\r\")           \n",
    "            self.thetas = thetas_new\n",
    "            \n",
    "        self.thetas -= self.thetas[0] # level normalization of thetas\n",
    "        \n",
    "        # calculating all possible utilities for all individuals\n",
    "        util = self.thetas.transpose() + self.choicesets @ betas \n",
    "        \n",
    "        # calculate LL based on actual choice\n",
    "        loglikes = self.thetas[self.locs] + self.choices @ betas - np.log(np.exp(util).sum(axis=1)) \n",
    "        self.LL = loglikes.sum() # store LL incase we need to check\n",
    "        print(\"LL: %.3f\" %(self.LL), end = \"\\r\")\n",
    "        return -self.LL\n",
    "\n",
    "    def MLL(self):\n",
    "        \"\"\"\n",
    "        Performs maximization routine given an optimizer (L-BFGS-B is default). \n",
    "        Bounds are optional.\n",
    "        \"\"\"\n",
    "        if self.bnds is None:\n",
    "            soln = minimize(self.NLL, self.betas, method = self.method, options={\"disp\": True})\n",
    "        else:\n",
    "            soln = minimize(self.NLL, self.betas, method = self.method, bounds = self.bnds, options={\"disp\": True})\n",
    "        self.betas = soln.x\n",
    "        \n",
    "npar = 5 # hardcode number of utility parameters\n",
    "tol = 1e-6\n",
    "# bnds = [(-2,2) for i in range(npar)]\n",
    "\n",
    "# initialize utility parameters to zero\n",
    "thetas0 = np.zeros(nlocs) \n",
    "betas0 = np.zeros(npar)\n",
    "\n",
    "BLP_Estimator_2_iii = BLP_Estimator(X, I, Z, L, betas0, thetas0, npar, tolerance = tol)\n",
    "BLP_Estimator_2_iii.MLL() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive BLP Estimates:\n",
      "\n",
      "First-Stage Estimates:\n",
      "cost: -0.123131\n",
      "kids*panfish: -0.142550\n",
      "kids*restroom: 0.617638\n",
      "boat*ramp: 1.453701\n",
      "boat*walleye: 0.526558\n",
      "\n",
      "Second-Stage Estimates:\n",
      "ramp: -0.533256\n",
      "restroom: -0.749538\n",
      "walleye: 2.125778\n",
      "salmon: 2.375341\n",
      "panfish: 0.524876\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive BLP Estimates:\\n\")\n",
    "\n",
    "names = [\"cost\", \"kids*panfish\", \"kids*restroom\", \"boat*ramp\", \"boat*walleye\"] \n",
    "print(\"First-Stage Estimates:\")\n",
    "for val, name in zip(BLP_Estimator_2_iii.betas, names):\n",
    "    print(\"%s: %f\" % (name, val))\n",
    "    \n",
    "lm = LinearRegression()\n",
    "lm.fit(y=BLP_Estimator_2_iii.thetas, X=X.drop(columns=\"shares\"))\n",
    "print(\"\\nSecond-Stage Estimates:\")\n",
    "for name, val in zip(X.drop(columns=\"shares\").columns, lm.coef_):\n",
    "    print(\"%s: %f\" % (name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL: -10457.092     \r"
     ]
    }
   ],
   "source": [
    "class Rand_BLP_Estimator(BLP_Estimator):\n",
    "    def __init__(self, X, I, Z, L, betas0, sigma0, thetas0, npar, randpar, sample_size = 1000,\n",
    "                 bnds = None, tolerance = 1e-5, method = \"L-BFGS-B\"):\n",
    "        super().__init__(X, I, Z, L, betas0, thetas0, npar, bnds, tolerance, method)\n",
    "        self.nsamp = sample_size\n",
    "        self.sigma = sigma0\n",
    "        self.randpar = randpar\n",
    "    \n",
    "    def pred_p_j(self, betas_array):\n",
    "        \"\"\"\n",
    "        Returns predicted shares for all sites given a vector of utility parameters.\n",
    "        \"\"\"\n",
    "        p_j = np.zeros(self.nlocs)\n",
    "        util = self.thetas.reshape((self.nlocs,1)) + self.choicesets @ betas_array\n",
    "        for i in range(self.N):\n",
    "            prob = np.exp(util[i,:,:]) / np.exp(util[i,:,:]).sum(axis=0)\n",
    "            p_j += prob.mean(axis=1)\n",
    "        p_j /= self.N\n",
    "        return p_j\n",
    "\n",
    "    def NLL(self, par):\n",
    "        \"\"\" \n",
    "        Performs BLP contraction mapping and returns negative log-likelihood.\n",
    "        \"\"\"\n",
    "        \n",
    "        betas = par[0:self.npar] # store arbitrary vector of utility coefficients\n",
    "        sigma = par[self.npar:(self.npar + self.randpar)]\n",
    "        betas_array = np.repeat(np.reshape(betas,(self.npar,1)), self.nsamp, axis = 1)\n",
    "        \n",
    "        # sample random params\n",
    "        v = np.random.normal(0,sigma,self.nsamp)\n",
    "        betas_array = betas_array + np.vstack([np.zeros((npar - 1, self.nsamp)), v])\n",
    "        \n",
    "        d = np.repeat(1,self.nlocs)     # initializing some distance\n",
    "        \n",
    "        # BLP contraction mapping\n",
    "        while any(d > self.tol):\n",
    "            thetas_new = self.theta_update(betas_array)\n",
    "            d = np.abs(thetas_new - self.thetas)\n",
    "            print(\"D: %.8f     \" % (max(d)), end = \"\\r\")           \n",
    "            self.thetas = thetas_new\n",
    "            \n",
    "        self.thetas -= self.thetas[0] # level normalization of thetas\n",
    "        \n",
    "        # calculate LL based on actual choice\n",
    "        num = self.thetas[self.locs].reshape((self.N,1)) + self.choices @ betas_array\n",
    "        denom = self.thetas.reshape((self.nlocs,1)) + self.choicesets @ betas_array\n",
    "        like = np.exp(num) / np.exp(denom).sum(axis=1)\n",
    "        loglikes = np.log(like.mean(axis=1))\n",
    "        self.LL = loglikes.sum()\n",
    "\n",
    "        print(\"LL: %.3f\" %(self.LL), end = \"\\r\")\n",
    "        return -self.LL\n",
    "    \n",
    "    def MLL(self):\n",
    "        \"\"\"\n",
    "        Performs maximization routine given an optimizer (L-BFGS-B is default). \n",
    "        Bounds are optional.\n",
    "        \"\"\"\n",
    "        init = np.hstack([self.betas,self.sigma])\n",
    "        if self.bnds is None:\n",
    "            soln = minimize(self.NLL, init, method = self.method, options={\"disp\": True})\n",
    "        else:\n",
    "            soln = minimize(self.NLL, init, method = self.method, bounds = self.bnds, options={\"disp\": True})\n",
    "        self.betas = soln.x[0:self.npar]\n",
    "        self.sigma = soln.x[-1]\n",
    "\n",
    "npar = 5 # hardcode number of utility parameters\n",
    "tol = 1e-6\n",
    "bnds = [(None,None) for i in range(npar)]\n",
    "bnds.append((0,None))\n",
    "\n",
    "# initialize utility parameters to zero\n",
    "thetas0 = np.zeros(nlocs) \n",
    "betas0 = np.zeros(npar)\n",
    "\n",
    "# initialize random parameters\n",
    "randpar = 1\n",
    "sample_size = 500\n",
    "sigma0 = 0.1\n",
    "\n",
    "BLP_Estimator_2_iv = Rand_BLP_Estimator(X, I, Z, L, betas0, sigma0, thetas0, npar, randpar, \n",
    "                                        sample_size, bnds, tolerance = tol)\n",
    "BLP_Estimator_2_iv.MLL() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive BLP Estimates:\n",
      "\n",
      "First-Stage Estimates:\n",
      "cost: 0.000000\n",
      "kids*panfish: -0.000000\n",
      "kids*restroom: -0.000000\n",
      "boat*ramp: -0.000000\n",
      "boat*walleye: 0.000000\n",
      "\n",
      "sigma_walleye: 0.100000\n",
      "\n",
      "Second-Stage Estimates:\n",
      "ramp: 0.000381\n",
      "restroom: 0.102926\n",
      "walleye: 1.326915\n",
      "salmon: 3.356123\n",
      "panfish: 0.179537\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive BLP Estimates:\\n\")\n",
    "\n",
    "names = [\"cost\", \"kids*panfish\", \"kids*restroom\", \"boat*ramp\", \"boat*walleye\"] \n",
    "print(\"First-Stage Estimates:\")\n",
    "for val, name in zip(BLP_Estimator_2_iv.betas, names):\n",
    "    print(\"%s: %f\" % (name, val))\n",
    "print(\"\\nsigma_walleye: %f\" % (BLP_Estimator_2_iv.sigma))\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(y=BLP_Estimator_2_iv.thetas, X=X.drop(columns=\"shares\"))\n",
    "print(\"\\nSecond-Stage Estimates:\")\n",
    "for name, val in zip(X.drop(columns=\"shares\").columns, lm.coef_):\n",
    "    print(\"%s: %f\" % (name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. \n",
    "\n",
    "From each of the models, we see a consistent negative estimate for the marginal utility of travel cost parameter in the range of -0.10 to -0.12, which is consistent with our expectation that sites that are more costly to travel to are less attractive. \n",
    "\n",
    "Interestingly, from the first model we see that having a bathroom makes a site less attractive on average, with an estimated marginal disutility of -0.18, almost double the estimate of marginal disutility for travel costs.\n",
    "\n",
    "In line with what we would expect, better catch rates increase utility across the board. Salmon appears to be the most sought after fish, as a unit increase in the salmon catch rate is associated with an average increase in marginal utility of 4.6. This is followed by walleye (1.7) and panfish (0.39).\n",
    "\n",
    "Lastly, the first model shows little or no gain in marginal utility from the presence of a ramp at the site.\n",
    "\n",
    "### b. \n",
    "\n",
    "Our un-interacted estimates in the second model are mostly consistent with our estimates from our first model, the one big difference being that having a ramp now decreases the average attractiveness of the site for owners without a boat (-0.41). In the first model having a ramp increased average attractiveness for all owners, though negligibly. This difference is explained by the interaction term of ramp and boat, where we see owners with a boat experience an average increase in marginal utility of 0.1 when they go to sites with ramps (naturally, boat owners need ramps to use their boats). Without accounting for the difference in preferences between boat owners, these differences in marginal utility washed out. \n",
    "\n",
    "A similar effect occurs with the estimate for marginal utility from having restrooms. The average marginal disutility for restrooms jumps from -0.18 in the first model to -0.28 in the second model. The first estimate was biased towards zero by not accounting for the benefit fishers with children receive from sites with bathrooms. Having a bathroom increases the average utility for fishers with children by 0.34 (which makes sense, sites with bathrooms are probably more kid friendly in general).\n",
    "\n",
    "Lastly, we see a positive estimate for the interaction between having a boat and the walleye catch rate (0.7), which tells us fishing for walleye is a more enjoyable experience when in a boat, and a negative estimate for the interaction between the panfish cath rate and having children. This maybe tells us that it is hard for children to catch panfish, so if that is what is available at the site, it might be a worse place to bring children.\n",
    "\n",
    "### c. \n",
    "\n",
    "From the previous two questions, we see that it is not only important to account for observed heterogeneity in the site attributes, but it is also important to account for observed heterogeneity in individuals and how they interact with sites. We also see from the differences in the first two models that without including sources of unobserved heterogeneity, the parameters that we do include in the model will sop up any unobserved differences in sites and individuals. In the next question we see how our estimates differ upon including a source of unobserved site heterogeneity $(\\xi)$.\n",
    "\n",
    "### d. \n",
    "\n",
    "After accounting for unobserved site heterogeneity, our qualitative interpretations of the site attributes have not changed (no sign flips occur between the second and the third model). However, the magnitudes of certain effects have changed. \n",
    "\n",
    "With regards to individual specific estimates, we see that the average marginal disutility of travel cost has gone from -0.10 to -0.12. We also see that the average marginal utilities for \"kids x restroom\" and \"boat x ramp\" have jumped up from 0.34 to 0.62 and from 0.98 to 1.45 respectively, telling us that there is something unobserved at sites with ramps and restrooms that was being captured by these estimates before and biasing them downwards (perhaps more developed sites have worse natural amenities or are more congested). \n",
    "\n",
    "For the observable site attributes, after accounting for unobserved site heterogeneity we see a big change in the average disutility from a site having restroom (-0.28 vs. -0.75). This likely indicates that there are beneficial site attributes that are correlated with having a bathroom (e.g. other beneficial amenities that come with increased development, like a tackle shop), which were biasing the average disutility from having a bathroom towards zero. Lastly, we see that a higher catch rate for walleye is now worth more (increase to 2.12 from 1.29), while a higher catch rate for salmon is worth less (decrease from 4.56 to 2.38). So a site having more salmon is correlated with an unobserved and beneficial site attribute, while the opposite is likely true for walleye (maybe salmon tend to live in more naturally beautiful areas, while walleye do not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.i.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "choicesets = []\n",
    "for i in range(N):\n",
    "    choiceset = X.copy()\n",
    "    choiceset[\"shares x 100\"] = choiceset.shares * 100\n",
    "    choiceset.drop(columns = \"shares\", inplace = True)\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choicesets.append(choiceset)\n",
    "choicesets = np.stack(choicesets)\n",
    "\n",
    "choices = np.stack([choicesets[i,j,:] for i,j in zip(range(N), L.choice-1)])\n",
    "        \n",
    "npar = 7\n",
    "\n",
    "def NLL(par):\n",
    "    betas = par[0:npar]\n",
    "    util = choicesets @ betas\n",
    "    loglikes = choices @ betas - np.log(np.exp(util).sum(axis=1))\n",
    "    return -loglikes.sum()\n",
    "\n",
    "beta0 = np.repeat(0,npar)\n",
    "results = minimize(NLL, beta0, method = \"L-BFGS-B\", options={\"disp\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ramp: -0.009151\n",
      "restroom: -0.224821\n",
      "walleye: 0.174673\n",
      "salmon: 0.240314\n",
      "panfish: 0.230755\n",
      "shares x 100: 0.693769\n",
      "cost: -0.104435\n"
     ]
    }
   ],
   "source": [
    "for val, name in zip(results.x, choiceset.columns):\n",
    "    print(\"%s: %f\" % (name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.i.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "choicesets = []\n",
    "for i in range(N):\n",
    "    choiceset = X.copy()\n",
    "    choiceset[\"shares*100\"] = choiceset.shares * 100\n",
    "    choiceset.drop(columns = \"shares\", inplace = True)\n",
    "    choiceset[\"kids*panfish\"] = choiceset.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = choiceset.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = choiceset.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = choiceset.walleye * I.loc[i, \"boat\"]\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choicesets.append(choiceset)\n",
    "choicesets = np.stack(choicesets)\n",
    "\n",
    "choices = np.stack([choicesets[i,j,:] for i,j in zip(range(N), L.choice-1)])\n",
    "\n",
    "npar = 11\n",
    "\n",
    "beta0 = np.repeat(0,npar)\n",
    "results = minimize(NLL, beta0, method = \"L-BFGS-B\", options={\"disp\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ramp: -0.508705\n",
      "restroom: -0.319633\n",
      "walleye: -0.213645\n",
      "salmon: 0.159423\n",
      "panfish: 0.266962\n",
      "shares*100: 0.695230\n",
      "kids*panfish: -0.127192\n",
      "kids*restroom: 0.372497\n",
      "boat*ramp: 1.048762\n",
      "boat*walleye: 0.600612\n",
      "cost: -0.104453\n"
     ]
    }
   ],
   "source": [
    "for val, name in zip(results.x, choiceset.columns):\n",
    "    print(\"%s: %f\" % (name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.i.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive BLP Estimates:\n",
      "\n",
      "First-Stage Estimates:\n",
      "cost: -0.123131\n",
      "kids*panfish: -0.142550\n",
      "kids*restroom: 0.617638\n",
      "boat*ramp: 1.453701\n",
      "boat*walleye: 0.526558\n",
      "\n",
      "Second-Stage Estimates:\n",
      "ramp: -0.559304\n",
      "restroom: -0.791782\n",
      "walleye: 0.991091\n",
      "salmon: -0.983832\n",
      "panfish: 0.383274\n",
      "shares x 100: 0.700870\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive BLP Estimates:\\n\")\n",
    "\n",
    "names = [\"cost\", \"kids*panfish\", \"kids*restroom\", \"boat*ramp\", \"boat*walleye\"] \n",
    "print(\"First-Stage Estimates:\")\n",
    "for val, name in zip(BLP_Estimator_2_iii.betas, names):\n",
    "    print(\"%s: %f\" % (name, val))\n",
    "    \n",
    "X_shares = X.copy()\n",
    "X_shares[\"shares x 100\"] = X_shares.shares * 100\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(y=BLP_Estimator_2_iii.thetas, X=X_shares.drop(columns=\"shares\"))\n",
    "print(\"\\nSecond-Stage Estimates:\")\n",
    "for name, val in zip(X_shares.drop(columns=\"shares\").columns, lm.coef_):\n",
    "    print(\"%s: %f\" % (name, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each of the three models, we get that an increase in the share of anglers choosing site $j$ is associated with an increase to average marginal utility from choosing site $j$ in the range of 0.6 - 0.7. This counterintuitively indicates an agglomeration effect (having not accounted for the endogeneity of the share choosing each site). \n",
    "\n",
    "In the first model, we see a dramatic decrease in the average marginal utility associated with each catch rate. Sites with better catch rates probably attract more anglers, thus increasing the share choosing those sites. So the model thinks more anglers choosing a site explains the appeal of the site, when really it is the site attributes that explain why more anglers choose it, and the former relationship is endogenous. In the second and third models, this effect is even more dramatic with the signs of multiple estimates for the average marginal utility of catch rates flipping negative. The fact that we are only seeing this effect with the estimates for catch rates is an indication that catch rates are the attributes that interact with congestion (anglers are worried about fish being depleted by other anglers, not restrooms or ramp space). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>IV-GMM Estimation Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>dependent</td>    <th>  R-squared:         </th> <td>-5.3884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Estimator:</th>             <td>IV-GMM</td>      <th>  Adj. R-squared:    </th> <td>-5.8006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>        <td>100</td>       <th>  F-statistic:       </th> <td>9.1246</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, Dec 17 2019</td> <th>  P-value (F-stat)   </th> <td>0.1667</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:26:33</td>     <th>  Distribution:      </th> <td>chi2(6)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td></td>         <th>                     </th>    <td></td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Parameter Estimates</caption>\n",
       "<tr>\n",
       "      <td></td>     <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th>  <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ramp</th>      <td>-0.3715</td>   <td>0.7364</td>   <td>-0.5045</td> <td>0.6139</td>   <td>-1.8149</td>  <td>1.0718</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>restroom</th>  <td>-0.4873</td>   <td>0.7838</td>   <td>-0.6217</td> <td>0.5341</td>   <td>-2.0235</td>  <td>1.0489</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>walleye</th>   <td>9.1704</td>    <td>4.2159</td>   <td>2.1752</td>  <td>0.0296</td>   <td>0.9073</td>   <td>17.433</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>salmon</th>    <td>23.230</td>    <td>14.021</td>   <td>1.6568</td>  <td>0.0976</td>   <td>-4.2510</td>  <td>50.712</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>panfish</th>   <td>1.4040</td>    <td>0.5184</td>   <td>2.7083</td>  <td>0.0068</td>   <td>0.3879</td>   <td>2.4201</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>-1.0433</td>   <td>0.9478</td>   <td>-1.1009</td> <td>0.2710</td>   <td>-2.9009</td>  <td>0.8142</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shares</th>    <td>-4.3513</td>   <td>2.2506</td>   <td>-1.9334</td> <td>0.0532</td>   <td>-8.7623</td>  <td>0.0598</td> \n",
       "</tr>\n",
       "</table><br/><br/>Endogenous: shares<br/>Instruments: shares<br/>GMM Covariance<br/>Debiased: False<br/>Robust (Heteroskedastic)<br/>id: 0x1d77b786080"
      ],
      "text/plain": [
       "                          IV-GMM Estimation Summary                           \n",
       "==============================================================================\n",
       "Dep. Variable:              dependent   R-squared:                     -5.3884\n",
       "Estimator:                     IV-GMM   Adj. R-squared:                -5.8006\n",
       "No. Observations:                 100   F-statistic:                    9.1246\n",
       "Date:                Tue, Dec 17 2019   P-value (F-stat)                0.1667\n",
       "Time:                        22:26:33   Distribution:                  chi2(6)\n",
       "Cov. Estimator:                robust                                         \n",
       "                                                                              \n",
       "                             Parameter Estimates                              \n",
       "==============================================================================\n",
       "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
       "------------------------------------------------------------------------------\n",
       "ramp          -0.3715     0.7364    -0.5045     0.6139     -1.8149      1.0718\n",
       "restroom      -0.4873     0.7838    -0.6217     0.5341     -2.0235      1.0489\n",
       "walleye        9.1704     4.2159     2.1752     0.0296      0.9073      17.433\n",
       "salmon         23.230     14.021     1.6568     0.0976     -4.2510      50.712\n",
       "panfish        1.4040     0.5184     2.7083     0.0068      0.3879      2.4201\n",
       "const         -1.0433     0.9478    -1.1009     0.2710     -2.9009      0.8142\n",
       "shares        -4.3513     2.2506    -1.9334     0.0532     -8.7623      0.0598\n",
       "==============================================================================\n",
       "\n",
       "Endogenous: shares\n",
       "Instruments: shares\n",
       "GMM Covariance\n",
       "Debiased: False\n",
       "Robust (Heteroskedastic)\n",
       "IVGMMResults, id: 0x1d77b786080"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choicesets = []\n",
    "for i in range(N):\n",
    "    choiceset = X.drop(columns=\"shares\")\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = choiceset.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = choiceset.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = choiceset.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = choiceset.walleye * I.loc[i, \"boat\"]\n",
    "    choicesets.append(choiceset)\n",
    "choicesets = np.stack(choicesets)\n",
    "\n",
    "choices = np.stack([choicesets[i,j,:] for i,j in zip(range(N), L.choice-1)])\n",
    "\n",
    "### generating instruments ###\n",
    "exog = X.copy()\n",
    "exog[\"shares x 100\"] = exog.shares * 100\n",
    "exog[\"constant\"] = np.ones(exog.shape[0])\n",
    "exog.drop(columns=\"shares\", inplace=True)\n",
    "\n",
    "# median regression\n",
    "qlm = QuantReg(BLP_Estimator_2_iii.thetas, exog)\n",
    "instrument = qlm.fit(0.5)\n",
    "\n",
    "# share intruments\n",
    "const = instrument.params[-1]\n",
    "betas = np.concatenate([instrument.params[0:-2], BLP_Estimator_2_iii.betas])\n",
    "util = const + choicesets @ betas\n",
    "p_ij = np.exp(util).transpose() / np.exp(util).sum(axis=1)\n",
    "pred_shares = p_ij.sum(axis=1) / N\n",
    "\n",
    "### GMM ###\n",
    "exog = X.drop(columns=\"shares\")\n",
    "exog[\"const\"] = 1\n",
    "iv = pd.DataFrame({\"shares\" : pred_shares * 100})\n",
    "mod_iv = IVGMM(BLP_Estimator_2_iii.thetas,\n",
    "                exog,\n",
    "                X.shares * 100,\n",
    "                iv)\n",
    "\n",
    "results_iv = mod_iv.fit(cov_type=\"robust\")\n",
    "results_iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now observe the expected result, i.e. the estimate on shares x 100 is now negative, indicating a congestion effect. Our estimates on the catch rates for walleyy (9.17), salmon (23.23), and panfish (1.40) are all now significantly larger than before. This is due to the fact that catch rates are probably highly correlated with congestion, so when we weren't accounting for the effect of congestion before the model could not disentangle the beneficial effect of an increase in the catch rates from the correlated increase in congestion costs. Thus, estimates for the average marginal utility from increases to catch rates were being biased towards zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "## 4.i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_PE = {}\n",
    "\n",
    "alpha = np.abs(BLP_Estimator_2_iii.betas[0])\n",
    "betas = BLP_Estimator_2_iii.betas\n",
    "thetas = BLP_Estimator_2_iii.thetas\n",
    "xi = results_iv.resids.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "choicesets = []\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X.walleye * I.loc[i, \"boat\"]\n",
    "    choicesets.append(choiceset)\n",
    "choicesets = np.stack(choicesets)\n",
    "\n",
    "new_choicesets = []\n",
    "X_new = X.copy()\n",
    "X_new.walleye = X_new.walleye * 1.3\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X_new.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X_new.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X_new.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X_new.walleye * I.loc[i, \"boat\"] \n",
    "    new_choicesets.append(choiceset)\n",
    "new_choicesets = np.stack(new_choicesets)\n",
    "\n",
    "old_util = np.exp(thetas + choicesets @ betas).mean(axis=1)\n",
    "exog = X_new.drop(columns=\"shares\")\n",
    "exog[\"const\"] = 1\n",
    "exog.walleye = exog.walleye * 1.3\n",
    "endog = X_new.shares * 100\n",
    "new_util = np.exp(xi + results_iv.predict(exog,endog).values.squeeze() + new_choicesets @ betas).mean(axis=1)\n",
    "\n",
    "CV_PE[\"Scenario A\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "choicesets_change = []\n",
    "choicesets_nochange = []\n",
    "\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X.walleye * I.loc[i, \"boat\"]\n",
    "    if X.shares[L.choice[i] - 1] > 0.015:\n",
    "        choicesets_change.append(choiceset)\n",
    "    else:\n",
    "        choicesets_nochange.append(choiceset)\n",
    "        \n",
    "choicesets_change = np.stack(choicesets_change)\n",
    "choicesets_nochange = np.stack(choicesets_nochange)\n",
    "\n",
    "new_choicesets_change = []\n",
    "new_choicesets_nochange = []\n",
    "X_new = X.copy()\n",
    "X_new.walleye = X_new.walleye * np.where(X_new.shares > 0.015, 1.3, 1)\n",
    "\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X_new.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X_new.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X_new.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X_new.walleye * I.loc[i, \"boat\"]\n",
    "    if X.shares[L.choice[i] - 1] > 0.015:\n",
    "        new_choicesets_change.append(choiceset)\n",
    "    else:\n",
    "        new_choicesets_nochange.append(choiceset)\n",
    "        \n",
    "new_choicesets_change = np.stack(new_choicesets_change)\n",
    "new_choicesets_nochange = np.stack(new_choicesets_nochange)\n",
    "\n",
    "exog = X_new.drop(columns=\"shares\")\n",
    "exog[\"const\"] = 1\n",
    "exog.walleye = exog.walleye * np.where(X_new.shares > 0.015, 1.3, 1)\n",
    "endog = X_new.shares * 100\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_change @ betas).mean(axis=1)\n",
    "new_util = np.exp(xi + results_iv.predict(exog,endog).values.squeeze() + new_choicesets_change @ betas).mean(axis=1)\n",
    "\n",
    "CV_PE[\"Scenario B, Affected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_nochange @ betas).mean(axis=1)\n",
    "new_util = np.exp(xi + results_iv.predict(exog,endog).values.squeeze() + new_choicesets_nochange @ betas).mean(axis=1)\n",
    "\n",
    "CV_PE[\"Scenario B, Unaffected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "choicesets = []\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X.walleye * I.loc[i, \"boat\"]\n",
    "    if X.shares[L.choice[i] - 1] <= 0.015:\n",
    "        choicesets.append(choiceset)\n",
    "\n",
    "choicesets = np.stack(choicesets)\n",
    "\n",
    "new_choicesets = []\n",
    "\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X_new.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X_new.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X_new.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X_new.walleye * I.loc[i, \"boat\"]\n",
    "    choiceset = choiceset[X.shares <= 1.5]\n",
    "    \n",
    "    if X.shares[L.choice[i] - 1] <= 0.015:\n",
    "        new_choicesets.append(choiceset)\n",
    "\n",
    "new_choicesets = np.stack(new_choicesets)\n",
    "\n",
    "old_util = np.exp(thetas + choicesets @ betas).mean(axis=1)\n",
    "exog = X[X.shares <= 0.15]\n",
    "exog[\"const\"] = 1\n",
    "endog = exog.shares * 100\n",
    "exog.drop(columns=\"shares\",inplace=True)\n",
    "\n",
    "new_util = np.exp(xi[X.shares <= 0.15] + results_iv.predict(exog,endog).values.squeeze() + new_choicesets @ betas).mean(axis=1)\n",
    "\n",
    "CV_PE[\"Scenario C\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "choicesets_change = []\n",
    "choicesets_nochange = []\n",
    "\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X.walleye * I.loc[i, \"boat\"]\n",
    "    if X.shares[L.choice[i] - 1] > 0.015:\n",
    "        choicesets_change.append(choiceset)\n",
    "    else:\n",
    "        choicesets_nochange.append(choiceset)\n",
    "        \n",
    "choicesets_change = np.stack(choicesets_change)\n",
    "choicesets_nochange = np.stack(choicesets_nochange)\n",
    "\n",
    "new_choicesets_change = []\n",
    "new_choicesets_nochange = []\n",
    "\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values + np.where(X.shares > 0.015, 10, 0)\n",
    "    choiceset[\"kids*panfish\"] = X.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X.walleye * I.loc[i, \"boat\"]\n",
    "    if X.shares[L.choice[i] - 1] > 0.015:\n",
    "        new_choicesets_change.append(choiceset)\n",
    "    else:\n",
    "        new_choicesets_nochange.append(choiceset)\n",
    "        \n",
    "new_choicesets_change = np.stack(new_choicesets_change)\n",
    "new_choicesets_nochange = np.stack(new_choicesets_nochange)\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_change @ betas).mean(axis=1)\n",
    "new_util = np.exp(thetas + new_choicesets_change @ betas).mean(axis=1)\n",
    "\n",
    "CV_PE[\"Scenario D, Affected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_nochange @ betas).mean(axis=1)\n",
    "new_util = np.exp(thetas + new_choicesets_nochange @ betas).mean(axis=1)\n",
    "\n",
    "CV_PE[\"Scenario D, Unaffected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_GE = {}\n",
    "\n",
    "def pred_shares(xi, exog, endog, choicesets, betas, niter):\n",
    "    for _ in range(niter):\n",
    "        util = xi + results_iv.predict(exog,endog*100).values.squeeze() + choicesets @ betas\n",
    "        p_ij = np.exp(util).transpose() / np.exp(util).sum(axis=1)\n",
    "        p_j = p_ij.mean(axis=1)\n",
    "        endog = p_j\n",
    "    return p_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "choicesets = []\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X.walleye * I.loc[i, \"boat\"]\n",
    "    choicesets.append(choiceset)\n",
    "choicesets = np.stack(choicesets)\n",
    "\n",
    "new_choicesets = []\n",
    "X_new = X.copy()\n",
    "X_new.walleye = X_new.walleye * 1.3\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X_new.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X_new.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X_new.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X_new.walleye * I.loc[i, \"boat\"] \n",
    "    new_choicesets.append(choiceset)\n",
    "new_choicesets = np.stack(new_choicesets)\n",
    "\n",
    "old_util = np.exp(thetas + choicesets @ betas).mean(axis=1)\n",
    "exog = X_new.drop(columns=\"shares\")\n",
    "exog[\"const\"] = 1\n",
    "endog = pred_shares(xi, exog, X_new.shares, new_choicesets, betas, 1001)\n",
    "\n",
    "new_util = np.exp(xi + results_iv.predict(exog,endog).values.squeeze() + new_choicesets @ betas).mean(axis=1)\n",
    "\n",
    "CV_GE[\"Scenario A\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "choicesets_change = []\n",
    "choicesets_nochange = []\n",
    "\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X.walleye * I.loc[i, \"boat\"]\n",
    "    if X.shares[L.choice[i] - 1] > 0.015:\n",
    "        choicesets_change.append(choiceset)\n",
    "    else:\n",
    "        choicesets_nochange.append(choiceset)\n",
    "        \n",
    "choicesets_change = np.stack(choicesets_change)\n",
    "choicesets_nochange = np.stack(choicesets_nochange)\n",
    "\n",
    "new_choicesets_change = []\n",
    "new_choicesets_nochange = []\n",
    "\n",
    "X_new = X.copy()\n",
    "X_new.walleye = X_new.walleye * np.where(X_new.shares > 1.5, 1.3, 1)\n",
    "\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X_new.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X_new.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X_new.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X_new.walleye * I.loc[i, \"boat\"] \n",
    "    if X.shares[L.choice[i] - 1] > 0.015:\n",
    "        new_choicesets_change.append(choiceset)\n",
    "    else:\n",
    "        new_choicesets_nochange.append(choiceset)\n",
    "\n",
    "new_choicesets_change = np.stack(new_choicesets_change)\n",
    "new_choicesets_nochange = np.stack(new_choicesets_nochange)\n",
    "\n",
    "exog = X_new.drop(columns=\"shares\")\n",
    "exog[\"const\"] = 1\n",
    "endog = pred_shares(xi, exog, X_new.shares, new_choicesets, betas, 1001)\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_change @ betas).mean(axis=1)\n",
    "new_util = np.exp(xi + results_iv.predict(exog,endog).values.squeeze() + new_choicesets_change @ betas).mean(axis=1)\n",
    "\n",
    "CV_GE[\"Scenario B, Affected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_nochange @ betas).mean(axis=1)\n",
    "new_util = np.exp(xi + results_iv.predict(exog,endog).values.squeeze() + new_choicesets_nochange @ betas).mean(axis=1)\n",
    "\n",
    "CV_GE[\"Scenario B, Unaffected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_choicesets = []\n",
    "\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values\n",
    "    choiceset[\"kids*panfish\"] = X.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X.walleye * I.loc[i, \"boat\"] \n",
    "    choiceset = choiceset[X.shares <= 0.015]\n",
    "    new_choicesets.append(choiceset)\n",
    "\n",
    "new_choicesets = np.stack(new_choicesets)\n",
    "\n",
    "exog = X[X.shares <= 0.015].drop(columns=\"shares\")\n",
    "exog[\"const\"] = 1\n",
    "exog = exog.values\n",
    "endog = X[X.shares <= 0.015].shares.values\n",
    "endog = pred_shares(xi[X.shares <= 0.015], exog, endog, new_choicesets, betas, 1000)\n",
    "\n",
    "new_choicesets_change = new_choicesets[X.shares[L.choice - 1] > 0.015,:,:]\n",
    "new_choicesets_nochange = new_choicesets[X.shares[L.choice - 1] <= 0.015,:,:]\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_change @ betas).mean(axis=1)\n",
    "new_util = np.exp(xi[X_new.shares <= 0.015] + results_iv.predict(exog,endog).values.squeeze() + new_choicesets_change @ betas).mean(axis=1)\n",
    "\n",
    "CV_GE[\"Scenario C, Affected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_nochange @ betas).mean(axis=1)\n",
    "new_util = np.exp(xi[X_new.shares <= 0.015] + results_iv.predict(exog,endog).values.squeeze() + new_choicesets_nochange @ betas).mean(axis=1)\n",
    "\n",
    "CV_GE[\"Scenario C, Unaffected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_choicesets = []\n",
    "\n",
    "for i in range(N):\n",
    "    choiceset = pd.DataFrame()\n",
    "    choiceset[\"cost\"] = Z.iloc[i,].values + np.where(X.shares > 0.015, 10, 0)\n",
    "    choiceset[\"kids*panfish\"] = X.panfish * I.loc[i, \"kids\"]\n",
    "    choiceset[\"kids*restroom\"] = X.restroom * I.loc[i, \"kids\"]\n",
    "    choiceset[\"boat*ramp\"] = X.ramp * I.loc[i, \"boat\"]\n",
    "    choiceset[\"boat*walleye\"] = X.walleye * I.loc[i, \"boat\"] \n",
    "    new_choicesets.append(choiceset)\n",
    "\n",
    "new_choicesets = np.stack(new_choicesets)\n",
    "\n",
    "exog = X.drop(columns=\"shares\")\n",
    "exog[\"const\"] = 1\n",
    "exog = exog.values\n",
    "endog = X.shares.values\n",
    "endog = pred_shares(xi, exog, endog, new_choicesets, betas, 1000)\n",
    "\n",
    "new_choicesets_change = new_choicesets[X.shares[L.choice - 1] > 0.015,:,:]\n",
    "new_choicesets_nochange = new_choicesets[X.shares[L.choice - 1] <= 0.015,:,:]\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_change @ betas).mean(axis=1)\n",
    "new_util = np.exp(xi + results_iv.predict(exog,endog).values.squeeze() + new_choicesets_change @ betas).mean(axis=1)\n",
    "\n",
    "CV_GE[\"Scenario D, Affected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))\n",
    "\n",
    "old_util = np.exp(thetas + choicesets_nochange @ betas).mean(axis=1)\n",
    "new_util = np.exp(xi + results_iv.predict(exog,endog).values.squeeze() + new_choicesets_nochange @ betas).mean(axis=1)\n",
    "\n",
    "CV_GE[\"Scenario D, Unaffected\"] = np.mean(1/alpha * (np.log(new_util) - np.log(old_util)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial Equilibrium Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario A: 17.406\n",
      "Scenario B, Affected: 17.368\n",
      "Scenario B, Unaffected: 13.390\n",
      "Scenario C: 0.074\n",
      "Scenario D, Affected: -4.568\n",
      "Scenario D, Unaffected: -2.342\n"
     ]
    }
   ],
   "source": [
    "for key in CV_PE.keys():\n",
    "    print(\"%s: %.3f\" % (key, CV_PE.get(key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Equilibrium Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario A: 108.200\n",
      "Scenario B, Affected: 110.086\n",
      "Scenario B, Unaffected: 101.554\n",
      "Scenario C, Affected: 27.993\n",
      "Scenario C, Unaffected: 32.200\n",
      "Scenario D, Affected: 85.732\n",
      "Scenario D, Unaffected: 76.305\n"
     ]
    }
   ],
   "source": [
    "for key in CV_GE.keys():\n",
    "    print(\"%s: %.3f\" % (key, CV_GE.get(key)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
